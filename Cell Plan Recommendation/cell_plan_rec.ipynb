{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell plans recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data on the behavior of customers who have already switched to the Smart and Ultra tariffs (see our previous [study](https://github.com/Shurgalivan/Portfolio/blob/main/Cell%20Plan%20Selection/Cell_plan_selection_1.ipynb)). We need to build a model for the classification task that will select the appropriate tariff.\n",
    "\n",
    "In the study, we will construct a model with the maximum possible accuracy value, no less than 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "### Let's open the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the dataset in a dataframe `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Samples\n",
    "\n",
    "To train a model, we need to split the available data into different samples. Here we split the data into training, validation, and testing samples. The training sample is used to train the model, the validation sample is used to tune the model's hyperparameters and evaluate its performance during training, and the testing sample is used to assess the final performance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training sample with a size of 40%\n",
    "df_train, df_temp = train_test_split(df, test_size=0.40, random_state=12345)\n",
    "\n",
    "#validation and testing samples\n",
    "df_valid, df_test = train_test_split(df_temp, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model reasearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select out target variable `is_ultra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features without the target variable\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "#target variable\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)  \n",
    "target_valid = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the decision tree model. We will create a loop that, in each iteration, will create models and evaluate their accuracy at different depths of the decision tree, ranging from 2 to 20. We will use a step size of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 2 : 0.78227\n",
      "max_depth = 4 : 0.77916\n",
      "max_depth = 6 : 0.78383\n",
      "max_depth = 8 : 0.77916\n",
      "max_depth = 10 : 0.77449\n",
      "max_depth = 12 : 0.76205\n",
      "max_depth = 14 : 0.75894\n",
      "max_depth = 16 : 0.73406\n",
      "max_depth = 18 : 0.73095\n"
     ]
    }
   ],
   "source": [
    "for depth in range(2,20,2):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    print('max_depth =',depth,':', round(accuracy, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was achieved with a depth of 6, and it has an accuracy of 0.78383."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the models built using the Random Forest algorithm. We will once again run a loop, keeping the max_depth at 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2 : 0.78538\n",
      "n_estimators = 3 : 0.78383\n",
      "n_estimators = 4 : 0.78849\n",
      "n_estimators = 5 : 0.79471\n",
      "n_estimators = 6 : 0.79316\n",
      "n_estimators = 7 : 0.79471\n",
      "n_estimators = 8 : 0.79938\n",
      "n_estimators = 9 : 0.79938\n",
      "n_estimators = 10 : 0.80093\n",
      "n_estimators = 11 : 0.80093\n",
      "n_estimators = 12 : 0.80404\n",
      "n_estimators = 13 : 0.80249\n",
      "n_estimators = 14 : 0.80249\n",
      "n_estimators = 15 : 0.80093\n"
     ]
    }
   ],
   "source": [
    "for estimators in range(2,16):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=estimators, max_depth=6)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    print('n_estimators =',estimators,':', round(accuracy, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal number of trees in the forest, according to our loop, is 12, with an accuracy of 0.804. It seems like we have found the optimal hyperparameters. \n",
    "\n",
    "However, it is worth checking the model based on the logistic regression algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conduct an experiment with logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7107309486780715\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(features_train, target_train) \n",
    "predictions = model.predict(features_valid)\n",
    "#accuracy\n",
    "accuracy = accuracy_score(target_valid, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the accuracy of the logistic regression model is 0.71, which is lower than the accuracy achieved by the previous models. Unfortunately, it does not seem to be helpful with the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing rhe model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's evaluate the best model (Random Forest) on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select our features and target variable\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)  \n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = : 0.79938\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=8897, n_estimators=12, max_depth=6)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predictions = model.predict(features_test)\n",
    "accuracy = accuracy_score(target_test, predictions) \n",
    "print('accuracy =',':', round(accuracy,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the evaluation on the test dataset demonstrated the effectiveness of our Random Forest model with carefully selected hyperparameters. The error rate is slightly above 20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adequacy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the adequacy of the model, we can compare its performance with a baseline model or a random guessing approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = : 0.49767\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_predictions = np.random.randint(low = 0, high = 2, size = 643) \n",
    "accuracy = accuracy_score(target_test, random_predictions)\n",
    "print('accuracy =',':', round(accuracy,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our dataset, flipping a coin does not seem to be a more convenient or successful scenario. The model proposed in previous sections has proven to be effective and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "\n",
    "We conducted a machine learning model training using algorithms such as Random Forest, Decision Tree, and Logistic Regression.\n",
    "- The best-performing model was the Random Forest with hyperparameters 'n_estimators' (number of trees) set to 12 and 'max_depth' set to 6.\n",
    "- The best model was evaluated on the validation dataset and achieved an accuracy of over 0.79.\n",
    "- The model successfully passed the adequacy check, indicating that it outperformed a baseline model and demonstrated meaningful patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1192,
    "start_time": "2022-10-27T13:59:40.100Z"
   },
   {
    "duration": 78,
    "start_time": "2022-10-27T13:59:42.099Z"
   },
   {
    "duration": 19,
    "start_time": "2022-10-27T13:59:47.769Z"
   },
   {
    "duration": 44,
    "start_time": "2022-10-29T12:59:26.149Z"
   },
   {
    "duration": 1197,
    "start_time": "2022-10-29T12:59:29.662Z"
   },
   {
    "duration": 73,
    "start_time": "2022-10-29T12:59:31.552Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-29T12:59:36.138Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-29T12:59:38.286Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-29T13:13:53.537Z"
   },
   {
    "duration": 1124,
    "start_time": "2022-10-29T15:21:03.616Z"
   },
   {
    "duration": 184,
    "start_time": "2022-10-29T15:21:04.742Z"
   },
   {
    "duration": 16,
    "start_time": "2022-10-29T15:21:04.928Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-29T15:21:04.945Z"
   },
   {
    "duration": 17,
    "start_time": "2022-10-29T15:21:04.962Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-29T15:37:54.719Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-29T15:38:24.096Z"
   },
   {
    "duration": 132,
    "start_time": "2022-10-29T15:47:35.178Z"
   },
   {
    "duration": 51,
    "start_time": "2022-10-29T15:48:30.809Z"
   },
   {
    "duration": 114,
    "start_time": "2022-10-29T15:48:36.718Z"
   },
   {
    "duration": 103,
    "start_time": "2022-10-29T15:53:41.763Z"
   },
   {
    "duration": 78,
    "start_time": "2022-10-29T16:02:19.104Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-29T16:13:40.879Z"
   },
   {
    "duration": 115,
    "start_time": "2022-10-29T16:13:46.596Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-29T16:13:54.217Z"
   },
   {
    "duration": 385,
    "start_time": "2022-10-29T16:13:57.694Z"
   },
   {
    "duration": 400,
    "start_time": "2022-10-29T16:14:08.194Z"
   },
   {
    "duration": 492,
    "start_time": "2022-10-29T16:14:31.365Z"
   },
   {
    "duration": 392,
    "start_time": "2022-10-29T16:15:59.920Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-29T16:28:23.632Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-29T16:28:29.996Z"
   },
   {
    "duration": 28,
    "start_time": "2022-10-29T16:29:20.278Z"
   },
   {
    "duration": 1033,
    "start_time": "2022-10-30T09:40:18.934Z"
   },
   {
    "duration": 74,
    "start_time": "2022-10-30T09:40:19.969Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-30T09:40:20.044Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-30T09:40:20.060Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-30T09:40:20.067Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-30T09:40:20.075Z"
   },
   {
    "duration": 87,
    "start_time": "2022-10-30T09:40:20.081Z"
   },
   {
    "duration": 328,
    "start_time": "2022-10-30T09:40:20.170Z"
   },
   {
    "duration": 35,
    "start_time": "2022-10-30T09:40:20.499Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-30T09:48:38.232Z"
   },
   {
    "duration": 39,
    "start_time": "2022-10-30T10:00:50.838Z"
   },
   {
    "duration": 91,
    "start_time": "2022-10-30T10:03:56.373Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-30T10:04:08.466Z"
   },
   {
    "duration": 2,
    "start_time": "2022-10-30T10:04:44.978Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-30T10:04:48.557Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-30T10:05:15.435Z"
   },
   {
    "duration": 974,
    "start_time": "2022-10-30T10:21:48.082Z"
   },
   {
    "duration": 36,
    "start_time": "2022-10-30T10:21:49.058Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-30T10:21:49.095Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-30T10:21:49.111Z"
   },
   {
    "duration": 17,
    "start_time": "2022-10-30T10:21:49.120Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-30T10:21:49.138Z"
   },
   {
    "duration": 69,
    "start_time": "2022-10-30T10:21:49.146Z"
   },
   {
    "duration": 394,
    "start_time": "2022-10-30T10:21:49.216Z"
   },
   {
    "duration": 32,
    "start_time": "2022-10-30T10:21:49.612Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-30T10:21:49.646Z"
   },
   {
    "duration": 47,
    "start_time": "2022-10-30T10:21:49.651Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-30T10:21:49.700Z"
   },
   {
    "duration": 1070,
    "start_time": "2022-10-30T10:49:11.896Z"
   },
   {
    "duration": 36,
    "start_time": "2022-10-30T10:49:12.968Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-30T10:49:13.006Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-30T10:49:13.021Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-30T10:49:13.028Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-30T10:49:13.039Z"
   },
   {
    "duration": 80,
    "start_time": "2022-10-30T10:49:13.050Z"
   },
   {
    "duration": 333,
    "start_time": "2022-10-30T10:49:13.131Z"
   },
   {
    "duration": 22,
    "start_time": "2022-10-30T10:49:13.466Z"
   },
   {
    "duration": 20,
    "start_time": "2022-10-30T10:49:13.489Z"
   },
   {
    "duration": 78,
    "start_time": "2022-10-30T10:49:13.511Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-30T10:49:13.591Z"
   },
   {
    "duration": 1481,
    "start_time": "2022-10-30T11:12:00.775Z"
   },
   {
    "duration": 36,
    "start_time": "2022-10-30T11:12:02.258Z"
   },
   {
    "duration": 16,
    "start_time": "2022-10-30T11:12:02.298Z"
   },
   {
    "duration": 21,
    "start_time": "2022-10-30T11:12:02.316Z"
   },
   {
    "duration": 18,
    "start_time": "2022-10-30T11:12:02.338Z"
   },
   {
    "duration": 85,
    "start_time": "2022-10-30T11:12:02.357Z"
   },
   {
    "duration": 383,
    "start_time": "2022-10-30T11:12:02.444Z"
   },
   {
    "duration": 24,
    "start_time": "2022-10-30T11:12:02.838Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-30T11:12:02.863Z"
   },
   {
    "duration": 51,
    "start_time": "2022-10-30T11:12:02.876Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-30T11:12:02.929Z"
   },
   {
    "duration": 43,
    "start_time": "2022-11-03T08:53:07.135Z"
   },
   {
    "duration": 1558,
    "start_time": "2022-11-03T08:53:12.434Z"
   },
   {
    "duration": 39,
    "start_time": "2022-11-03T08:53:13.994Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-03T08:53:14.036Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-03T08:53:14.052Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-03T08:53:14.058Z"
   },
   {
    "duration": 88,
    "start_time": "2022-11-03T08:53:14.066Z"
   },
   {
    "duration": 347,
    "start_time": "2022-11-03T08:53:14.156Z"
   },
   {
    "duration": 32,
    "start_time": "2022-11-03T08:53:14.504Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-03T08:53:14.538Z"
   },
   {
    "duration": 39,
    "start_time": "2022-11-03T08:53:14.543Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-03T08:53:14.584Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
