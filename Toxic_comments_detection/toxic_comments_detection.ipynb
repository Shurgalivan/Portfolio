{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project for \"WikiShop\" (using BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The online store \"WikiShop\" is launching a new service. Now users can edit and enhance product descriptions, similar to wiki communities. In other words, customers can suggest their edits and comment on the changes made by others. The store requires a tool that can identify toxic comments and send them for moderation.\n",
    "\n",
    "The objective is to train a model using the BERT (Bidirectional Encoder Representations from Transformers) to classify comments as positive or negative. We have a labeled dataset available that indicates the toxicity of edits.\n",
    "\n",
    "We will build a model with an F1 quality metric value of at least 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ivanshurgalin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ivanshurgalin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/ivanshurgalin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import re\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dataset and save it in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will convert the texts to lowercase and remove unnecessary symbols, what would help to normalize the text and remove any inconsistencies or noise that might affect the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 159292/159292 [00:01<00:00, 80100.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalisms just closure on some gas after i voted at new york dolls fac and please dont remove the template from the talk page since im retired now'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_edit(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['text'] = df['text'].progress_apply(pre_edit)\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization and lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalisms just closure on some gas after i voted at new york dolls fac and please dont remove the template from the talk page since im retired now'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edit make under my username hardcore metallica fan be revert they werent vandalisms just closure on some gas after i vote at new york dolls fac and please dont remove the template from the talk page since im retire now'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_final'] = df.text.apply(lemmatize_text)\n",
    "df['text_final'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he match this background colour im seemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man im really not try to edit war its just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  explanation why the edits made under my userna...      0   \n",
       "1           1  daww he matches this background colour im seem...      0   \n",
       "2           2  hey man im really not trying to edit war its j...      0   \n",
       "3           3  more i cant make any real suggestions on impro...      0   \n",
       "4           4  you sir are my hero any chance you remember wh...      0   \n",
       "\n",
       "                                          text_final  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  daww he match this background colour im seemin...  \n",
       "2  hey man im really not try to edit war its just...  \n",
       "3  more i cant make any real suggestions on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edit make under my username hardcore metallica fan be revert they werent vandalisms just closure on some gas after i vote at new york dolls fac and please dont remove the template from the talk page since im retire now'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text after\n",
    "df['text_final'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's separate the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119469,), (39823,), (119469,), (39823,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comms = df['text_final']\n",
    "y_comms = df['toxic']\n",
    "\n",
    "x_train_comms, x_test_comms, y_train_comms, y_test_comms = train_test_split(x_comms, y_comms, random_state=0, \n",
    "                                                                            stratify=y_comms)\n",
    "x_train_comms.shape, x_test_comms.shape, y_train_comms.shape, y_test_comms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in the Training Dataset\n",
      "0.8983836811222995\n",
      "0.10161631887770049\n",
      "\n",
      "Class Distribution in the Test Dataset:\n",
      "0.8984004218667604\n",
      "0.10159957813323958\n"
     ]
    }
   ],
   "source": [
    "print('Class Distribution in the Training Dataset')\n",
    "print(y_train_comms.value_counts()[0] / y_train_comms.value_counts().sum())\n",
    "print(y_train_comms.value_counts()[1] / y_train_comms.value_counts().sum())\n",
    "print()\n",
    "print('Class Distribution in the Test Dataset:')\n",
    "print(y_test_comms.value_counts()[0] / y_test_comms.value_counts().sum())\n",
    "print(y_test_comms.value_counts()[1] / y_test_comms.value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a corpus and add stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ivanshurgalin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_comms_corpus = x_train_comms.values\n",
    "x_test_comms_corpus = x_test_comms.values\n",
    " \n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store the results, let's create a separate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Preprocessing model' : [], 'Learning model' : [], 'Train f1 score' : [], 'Test f1 score' : []\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    lgb.LGBMClassifier(n_estimators = 1000, learning_rate = 0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the models using a separate function `learn models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_models(models_list, x_train, y_train, x_test, y_test, prepr_model : str):\n",
    "    for i in models_list:\n",
    "        clf_gs = GridSearchCV(i, {}, cv=5, scoring='f1')\n",
    "        clf_gs.fit(x_train,y_train)\n",
    "        \n",
    "        train_f1_score = f1_score(y_train, clf_gs.predict(x_train))\n",
    "        test_f1_score = f1_score(y_test, clf_gs.predict(x_test))\n",
    "        \n",
    "        name = str(i).split(sep='(')[0]\n",
    "        \n",
    "        globals()['results'] = globals()['results'].append({\n",
    "            'Preprocessing model' : prepr_model, 'Learning model' : name, \n",
    "            'Train f1 score' : round(train_f1_score, 2), 'Test f1 score' : round(test_f1_score, 2)}, \n",
    "            ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 173887)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords, dtype=np.float32) \n",
    "\n",
    "x_train_comms_vectorized = vectorizer.fit_transform(x_train_comms_corpus)\n",
    "x_test_comms_vectorized = vectorizer.transform(x_test_comms_corpus)\n",
    "\n",
    "print(x_train_comms_vectorized.shape)\n",
    "print(x_train_comms_vectorized[:5].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/1f9vz20x39s2ctm4tynllrt00000gn/T/ipykernel_60695/2887302711.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 4s, sys: 2min 21s, total: 19min 26s\n",
      "Wall time: 3min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/1f9vz20x39s2ctm4tynllrt00000gn/T/ipykernel_60695/2887302711.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn_models(models, x_train_comms_vectorized, y_train_comms, x_test_comms_vectorized, y_test_comms,\n",
    "             prepr_model = 'CountVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "0     CountVectorizer  LogisticRegression            0.89           0.76\n",
       "1     CountVectorizer      LGBMClassifier            0.92           0.78"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "x_train_comms_tf_idf = tf_idf.fit_transform(x_train_comms)\n",
    "x_test_comms_tf_idf = tf_idf.transform(x_test_comms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 173887)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_comms_tf_idf.shape)\n",
    "print(x_train_comms_tf_idf[:5].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model and evaluate the time it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/1f9vz20x39s2ctm4tynllrt00000gn/T/ipykernel_60695/2887302711.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 56s, sys: 5min 13s, total: 48min 9s\n",
      "Wall time: 6min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/1f9vz20x39s2ctm4tynllrt00000gn/T/ipykernel_60695/2887302711.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn_models(models, x_train_comms_tf_idf, y_train_comms, x_test_comms_tf_idf, y_test_comms,\n",
    "             prepr_model = 'TfidfVectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "0     CountVectorizer  LogisticRegression            0.89           0.76\n",
       "1     CountVectorizer      LGBMClassifier            0.92           0.78\n",
       "2     TfidfVectorizer  LogisticRegression            0.76           0.74\n",
       "3     TfidfVectorizer      LGBMClassifier            0.95           0.78"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBert training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel, transformers.DistilBertTokenizer, \n",
    "                                                    'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2415ceb7a84c51884bf08d35b0d816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "tokenized = df['text_final'][:5000].progress_apply(lambda x: tokenizer.encode(x[:512], add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array([i + [0]*(512-len(i)) for i in tokenized.values])\n",
    "len(padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 512), (5000, 512))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "padded.shape, attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch sizw\n",
    "batch_size = 10\n",
    "# embeding\n",
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e44972cf444660977bb14b9fb498dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the training of the BERT model, we will take a subset of only 5000 rows from the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 768), (5000,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bert = np.concatenate(embeddings)\n",
    "y_bert = df['toxic'][:5000]\n",
    "x_bert.shape, y_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bert, x_test_bert, y_train_bert, y_test_bert = train_test_split(x_bert, y_bert, random_state=0, stratify=y_bert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/1f9vz20x39s2ctm4tynllrt00000gn/T/ipykernel_60695/2887302711.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 21s, sys: 33.5 s, total: 4min 54s\n",
      "Wall time: 43.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/1f9vz20x39s2ctm4tynllrt00000gn/T/ipykernel_60695/2887302711.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn_models(models, x_train_bert, y_train_bert, x_test_bert, y_test_bert,\n",
    "             prepr_model = 'DistilBert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And renew the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "0     CountVectorizer  LogisticRegression            0.89           0.76\n",
       "1     CountVectorizer      LGBMClassifier            0.92           0.78\n",
       "2     TfidfVectorizer  LogisticRegression            0.76           0.74\n",
       "3     TfidfVectorizer      LGBMClassifier            0.95           0.78\n",
       "4          DistilBert  LogisticRegression            0.81           0.66\n",
       "5          DistilBert      LGBMClassifier            1.00           0.65"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "1     CountVectorizer      LGBMClassifier            0.92           0.78\n",
       "3     TfidfVectorizer      LGBMClassifier            0.95           0.78\n",
       "0     CountVectorizer  LogisticRegression            0.89           0.76\n",
       "2     TfidfVectorizer  LogisticRegression            0.76           0.74\n",
       "4          DistilBert  LogisticRegression            0.81           0.66\n",
       "5          DistilBert      LGBMClassifier            1.00           0.65"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('Test f1 score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best-performing model was the LGBMClassifier on preprocessed text using the CountVectorizer preprocessing technique. Due to the use of a smaller dataset (5000 rows), the DistilBERT model might not have been able to learn complex patterns effectively, leading to the unsatisfactory results.e."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 56,
    "start_time": "2023-01-06T14:56:43.945Z"
   },
   {
    "duration": 2475,
    "start_time": "2023-01-08T09:59:56.146Z"
   },
   {
    "duration": 2267,
    "start_time": "2023-01-08T10:00:05.549Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-08T10:00:13.518Z"
   },
   {
    "duration": 28,
    "start_time": "2023-01-08T10:00:16.185Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-08T10:00:20.029Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:00:22.280Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:00:25.254Z"
   },
   {
    "duration": 383,
    "start_time": "2023-01-08T10:00:27.953Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:01:08.371Z"
   },
   {
    "duration": 145253,
    "start_time": "2023-01-08T10:01:11.088Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:04:37.396Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:05:52.436Z"
   },
   {
    "duration": 223,
    "start_time": "2023-01-08T10:06:03.938Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:06:54.720Z"
   },
   {
    "duration": 92608,
    "start_time": "2023-01-08T10:06:57.732Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:08:33.069Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:10:30.856Z"
   },
   {
    "duration": 94307,
    "start_time": "2023-01-08T10:10:36.435Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:12:40.616Z"
   },
   {
    "duration": 42,
    "start_time": "2023-01-08T10:25:10.844Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-08T10:25:15.011Z"
   },
   {
    "duration": 2273,
    "start_time": "2023-01-08T10:25:22.911Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:27:08.272Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:33:02.033Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:33:08.600Z"
   },
   {
    "duration": 245,
    "start_time": "2023-01-08T10:33:12.526Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:33:42.883Z"
   },
   {
    "duration": 47475,
    "start_time": "2023-01-08T10:33:46.408Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T10:35:14.973Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:41:48.788Z"
   },
   {
    "duration": 226,
    "start_time": "2023-01-08T10:41:52.662Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:46:27.242Z"
   },
   {
    "duration": 47445,
    "start_time": "2023-01-08T10:46:31.970Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-08T10:47:30.106Z"
   },
   {
    "duration": 933,
    "start_time": "2023-01-08T10:49:51.207Z"
   },
   {
    "duration": 61171,
    "start_time": "2023-01-08T10:50:07.482Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:51:11.175Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:51:15.350Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-08T10:51:20.161Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:56:17.938Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:58:17.105Z"
   },
   {
    "duration": 2,
    "start_time": "2023-01-08T10:58:29.937Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T10:58:51.504Z"
   },
   {
    "duration": 30443,
    "start_time": "2023-01-08T10:59:38.780Z"
   },
   {
    "duration": 298,
    "start_time": "2023-01-08T11:04:52.669Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-08T11:05:54.856Z"
   },
   {
    "duration": 47,
    "start_time": "2023-01-08T11:07:04.915Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T11:07:19.259Z"
   },
   {
    "duration": 28748,
    "start_time": "2023-01-08T11:07:22.767Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-08T11:12:30.751Z"
   },
   {
    "duration": 2416,
    "start_time": "2023-01-08T11:43:01.518Z"
   },
   {
    "duration": 787,
    "start_time": "2023-01-08T11:43:03.935Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-08T11:43:04.724Z"
   },
   {
    "duration": 30,
    "start_time": "2023-01-08T11:43:04.741Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-08T11:43:04.772Z"
   },
   {
    "duration": 2406,
    "start_time": "2023-01-08T11:43:04.779Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-08T11:43:07.187Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-08T11:43:07.192Z"
   },
   {
    "duration": 31010,
    "start_time": "2023-01-08T11:43:07.202Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-08T11:43:38.215Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-08T11:43:38.225Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-08T11:43:38.234Z"
   },
   {
    "duration": 85,
    "start_time": "2023-01-08T11:43:38.241Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-08T11:43:38.328Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-08T11:43:38.340Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-08T11:43:38.347Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-08T11:43:38.353Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-08T11:43:38.362Z"
   },
   {
    "duration": 6057,
    "start_time": "2023-01-08T11:43:38.370Z"
   },
   {
    "duration": 278949,
    "start_time": "2023-01-08T11:43:44.428Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-08T11:48:23.379Z"
   },
   {
    "duration": 6014,
    "start_time": "2023-01-08T11:48:23.386Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-08T11:48:29.401Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
